# -*- coding: utf-8 -*-
"""4B-IGNACIO-MP5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1STwh5WGiQcgz4xIS4crzurY8D_BCci-a

# **MACHINE PROBLEM 4**

**Name:** Maxyne Nuela Ignacio

**Year & Section:** BS Computer Science - IS - 4B

# **Install Libraries and Packages (SET UP)**
"""

!pip uninstall -y opencv-python opencv-python-headless opencv-contrib-python

!apt-get install -y cmake
!apt-get install -y libopencv-dev build-essential cmake git pkg-config libgtk-3-dev \
   libavcodec-dev libavformat-dev libswscale-dev libtbb2 libtbb-dev libjpeg-dev \
   libpng-dev libtiff-dev libdc1394-22-dev libv4l-dev v4l-utils \
   libxvidcore-dev libx264-dev libxine2-dev gstreamer1.0-tools \
   libgstreamer-plugins-base1.0-dev libgstreamer-plugins-good1.0-dev \
   libgtk2.0-dev libtiff5-dev libopenexr-dev libatlas-base-dev \
   python3-dev python3-numpy libtbb-dev libeigen3-dev \
   libfaac-dev libmp3lame-dev libtheora-dev libvorbis-dev \
   libxvidcore-dev libx264-dev yasm libopencore-amrnb-dev \
   libopencore-amrwb-dev libv4l-dev libxine2-dev libtesseract-dev \
   liblapacke-dev libopenblas-dev checkinstall

#Clone the OpenCV repository from GitHub.
!git clone https://github.com/opencv/opencv.git
!git clone https://github.com/opencv/opencv_contrib.git

# Commented out IPython magic to ensure Python compatibility.
#Change directory to the cloned OpenCV directory.
# %cd opencv
#Create a build directory for building the OpenCV source.
!mkdir build
#Move into the newly created build directory.
# %cd build

#Run the CMake configuration for building OpenCV with specific options:
!cmake -D CMAKE_BUILD_TYPE=RELEASE \
       -D CMAKE_INSTALL_PREFIX=/usr/local \
       -D OPENCV_ENABLE_NONFREE=ON \
       -D OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib/modules \
       -D BUILD_EXAMPLES=ON ..

#Compile OpenCV using 8 threads (parallel compilation) for faster build times.
!make -j8
#Install the compiled OpenCV library into the system.
!make install

# Commented out IPython magic to ensure Python compatibility.
# Step 1: Install required dependencies
!sudo apt update
!sudo apt install -y cmake g++ wget unzip

# Step 2: Download OpenCV and OpenCV contrib modules
!wget -O opencv.zip https://github.com/opencv/opencv/archive/refs/heads/4.x.zip
!wget -O opencv_contrib.zip https://github.com/opencv/opencv_contrib/archive/refs/heads/4.x.zip
!unzip opencv.zip
!unzip opencv_contrib.zip

# Step 3: Create a build directory
!mkdir -p opencv-4.x/build
# %cd opencv-4.x/build

# Step 4: Run CMake with the OPENCV_ENABLE_NONFREE flag
!cmake -D CMAKE_BUILD_TYPE=RELEASE \
        -D CMAKE_INSTALL_PREFIX=/usr/local \
        -D OPENCV_ENABLE_NONFREE=ON \
        -D OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib-4.x/modules \
        -D BUILD_EXAMPLES=OFF ..

# Step 5: Compile OpenCV (this step may take around 15-30 minutes)
!make -j8

# Step 6: Install OpenCV
!sudo make install
!sudo ldconfig

# Step 7: Verify installation
import cv2
print(cv2.__version__)

"""# **Task 1: Harris Corner Detection**

Load any grayscale image.

Apply the Harris Corner Detection algorithm to find corners.

Display the original image and the image with detected corners marked in red.

Function signature: def harris_corner_detection(image_path):
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from skimage.feature import hog
from skimage import exposure

image_path = "image01.jpg"

# Task 1: Harris Corner Detection
def harris_corner_detection(image_path):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    img_color = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
    dst = cv2.cornerHarris(img, 2, 3, 0.04)
    dst = cv2.dilate(dst, None)
    img_color[dst > 0.01 * dst.max()] = [0, 0, 255]  # Mark corners in red

    # Convert BGR to RGB for display
    img_color_rgb = cv2.cvtColor(img_color, cv2.COLOR_BGR2RGB)

    plt.figure(figsize=(10, 5))
    plt.subplot(1, 2, 1)
    plt.title("Original Image")
    plt.imshow(img, cmap='gray')
    plt.axis('off')
    plt.subplot(1, 2, 2)
    plt.title("Harris Corner Detection")
    plt.imshow(img_color_rgb)
    plt.axis('off')
    plt.show()

# Run the function
harris_corner_detection(image_path)

"""# **Task 2: HOG Feature Extraction**

Load an image of a person (or another object).

Convert the image to grayscale.

Extract HOG (Histogram of Oriented Gradients) features from the image.

Display the original image and the visualized HOG features.

Function signature: def hog_feature_extraction(image_path):
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from skimage.feature import hog
from skimage import exposure

# Task 2: HOG Feature Extraction
def hog_feature_extraction(image_path):
    # Ensure image is read in grayscale
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

    # Extract HOG features and the HOG visualization image
    hog_features, hog_image = hog(img, orientations=9, pixels_per_cell=(8, 8),
                                  cells_per_block=(2, 2), visualize=True)

    # Rescale intensity for better visualization of HOG image
    hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))

    # Plot the original image and HOG features
    plt.figure(figsize=(10, 5))
    plt.subplot(1, 2, 1)
    plt.title("Original Image")
    plt.imshow(img, cmap='gray')
    plt.axis('off')

    plt.subplot(1, 2, 2)
    plt.title("HOG Features")
    plt.imshow(hog_image_rescaled, cmap='gray')
    plt.axis('off')

    plt.show()

# Run the function
hog_feature_extraction("image01.jpg")

"""# **Task 3: ORB Feature Extraction and Matching**

Load two different images.

Apply ORB (Oriented FAST and Rotated BRIEF) to detect and compute keypoints and descriptors for both images.

Use the FLANN-based matcher to match the ORB descriptors of the two images.

Visualize the matching keypoints between the two images.

"""

import cv2
import matplotlib.pyplot as plt

# Task 3: ORB Feature Extraction and Matching
def orb_feature_matching():
    # Image paths
    image_path1 = "/content/image01.jpg"
    image_path2 = "/content/image02.jpg"


    # Read the images in grayscale
    img1 = cv2.imread(image_path1, cv2.IMREAD_GRAYSCALE)
    img2 = cv2.imread(image_path2, cv2.IMREAD_GRAYSCALE)

    # Verify that images were loaded
    if img1 is None:
        print(f"Error: Image at {image_path1} could not be loaded.")
        return
    if img2 is None:
        print(f"Error: Image at {image_path2} could not be loaded.")
        return

    # Initialize ORB detector
    orb = cv2.ORB_create()

    # Find the keypoints and descriptors with ORB
    kp1, des1 = orb.detectAndCompute(img1, None)
    kp2, des2 = orb.detectAndCompute(img2, None)

    # Use FLANN-based matcher with ORB-specific parameters
    index_params = dict(algorithm=6, table_number=6, key_size=12, multi_probe_level=1)
    search_params = {}
    flann = cv2.FlannBasedMatcher(index_params, search_params)
    matches = flann.knnMatch(des1, des2, k=2)

    # Apply ratio test to select good matches
    good_matches = []
    for m, n in matches:
        if m.distance < 0.7 * n.distance:
            good_matches.append(m)

    # Draw matches
    img_matches = cv2.drawMatches(img1, kp1, img2, kp2, good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)

    # Convert BGR to RGB for displaying with Matplotlib
    img_matches_rgb = cv2.cvtColor(img_matches, cv2.COLOR_BGR2RGB)

    # Plot the matching result
    plt.figure(figsize=(15, 10))
    plt.title("ORB Feature Matching")
    plt.imshow(img_matches_rgb)
    plt.axis('off')
    plt.show()

# Run the function
orb_feature_matching()

"""# **Task 4: SIFT and SURF Feature Extraction**

Load two images of your choice.

Apply both SIFT and SURF algorithms to detect keypoints and compute descriptors.

Visualize the keypoints detected by both methods in two separate images.

Function signature: def sift_and_surf_feature_extraction(image_path1, image_path2):
"""

import cv2
import matplotlib.pyplot as plt

def sift_feature_extraction(image_path1, image_path2):

    # Image paths
    image_path1 = "/content/image01.jpg"
    image_path2 = "/content/image02.jpg"

    # Read images in grayscale
    img1 = cv2.imread(image_path1, cv2.IMREAD_GRAYSCALE)
    img2 = cv2.imread(image_path2, cv2.IMREAD_GRAYSCALE)

    # Check if images are loaded correctly
    if img1 is None:
        print("Error: Image 1 could not be loaded. Please check the path.")
        return
    if img2 is None:
        print("Error: Image 2 could not be loaded. Please check the path.")
        return

    # Initialize SIFT detector
    sift = cv2.SIFT_create()

    # Detect keypoints and compute descriptors using SIFT
    kp_sift1, des_sift1 = sift.detectAndCompute(img1, None)
    kp_sift2, des_sift2 = sift.detectAndCompute(img2, None)

    # Draw SIFT keypoints
    img_sift1 = cv2.drawKeypoints(img1, kp_sift1, None)
    img_sift2 = cv2.drawKeypoints(img2, kp_sift2, None)

    # Convert images to RGB for Matplotlib
    img_sift1_rgb = cv2.cvtColor(img_sift1, cv2.COLOR_BGR2RGB)
    img_sift2_rgb = cv2.cvtColor(img_sift2, cv2.COLOR_BGR2RGB)

    # Plot SIFT keypoints
    plt.figure(figsize=(15, 5))
    plt.subplot(1, 2, 1)
    plt.title("SIFT Keypoints - Image 1")
    plt.imshow(img_sift1_rgb)
    plt.axis('off')

    plt.subplot(1, 2, 2)
    plt.title("SIFT Keypoints - Image 2")
    plt.imshow(img_sift2_rgb)
    plt.axis('off')

    plt.show()

# Run the function with two images
sift_feature_extraction("image01.jpg", "image02.jpg")

"""# **Task 5: Feature Matching using Brute-Force Matcher**

Load two images and extract ORB descriptors.

Match the descriptors using the Brute-Force Matcher.

Display the matched keypoints between the two images.

Function signature: def brute_force_feature_matching(image_path1, image_path2):
"""

import cv2
import matplotlib.pyplot as plt

def brute_force_feature_matching(image_path1, image_path2):
    # Load the two images
    img1 = cv2.imread(image_path1, cv2.IMREAD_GRAYSCALE)
    img2 = cv2.imread(image_path2, cv2.IMREAD_GRAYSCALE)

    # Check if images are loaded
    if img1 is None or img2 is None:
        print("Error: One or both images could not be loaded.")
        return

    # Initialize the ORB detector
    orb = cv2.ORB_create()

    # Detect and compute keypoints and descriptors
    keypoints1, descriptors1 = orb.detectAndCompute(img1, None)
    keypoints2, descriptors2 = orb.detectAndCompute(img2, None)

    # Initialize the Brute-Force matcher with default parameters
    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)

    # Match descriptors
    matches = bf.match(descriptors1, descriptors2)

    # Sort matches by distance for better visualization
    matches = sorted(matches, key=lambda x: x.distance)

    # Draw the first 50 matches
    matched_img = cv2.drawMatches(img1, keypoints1, img2, keypoints2, matches[:50], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)

    # Display the result
    plt.figure(figsize=(15, 10))
    plt.imshow(matched_img)
    plt.title("Feature Matching using ORB and Brute-Force Matcher")
    plt.axis("off")
    plt.show()

# Example usage with sample paths (replace with actual paths)
image_path1 = "/content/image01.jpg"
image_path2 = "/content/image02.jpg"
brute_force_feature_matching(image_path1, image_path2)

"""# **Task 6: Image Segmentation using Watershed Algorithm**

Load any image of your choice.

Convert the image to grayscale and apply a threshold to separate foreground from the background.

Apply the Watershed algorithm to segment the image into distinct regions.

Display the segmented image.

Function signature: def watershed_segmentation(image_path):
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
import os

def watershed_segmentation(image_path):
    # Check if the image exists at the given path
    if not os.path.exists(image_path):
        print(f"Error: Image file does not exist at path: {image_path}")
        return

    # Load the image
    image = cv2.imread(image_path)

    if image is None:
        print("Error: Image could not be loaded. Please check the path or file format.")
        return

    # Convert the image to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Apply thresholding to create a binary image
    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

    # Perform morphological operations to remove noise
    kernel = np.ones((3, 3), np.uint8)
    opening = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=2)

    # Identify sure background area using dilation
    sure_bg = cv2.dilate(opening, kernel, iterations=3)

    # Identify sure foreground area using distance transform
    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)
    _, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)
    sure_fg = np.uint8(sure_fg)

    # Identify unknown region
    unknown = cv2.subtract(sure_bg, sure_fg)

    # Marker labelling for watershed
    _, markers = cv2.connectedComponents(sure_fg)
    markers = markers + 1
    markers[unknown == 255] = 0

    # Apply the Watershed algorithm
    cv2.watershed(image, markers)

    # Mark the boundaries on the original image
    image[markers == -1] = [0, 0, 255]  # Boundary marked in red

    # Display the result
    plt.figure(figsize=(10, 10))
    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    plt.title("Segmented Image with Watershed")
    plt.axis("off")
    plt.show()

# Run the function with the path to the uploaded image
image_path = "/content/image01.jpg"
watershed_segmentation(image_path)